    // use crate::parser::token_type_lookup::*;
    // use crate::parser::enclosing_pairs::{
    //     initialize_enclosing_pairs,
    //     // split_at_enclosing_pair,
    //     find_enclosing_pair,
    //     // try_skip_string,
    //     // try_skip_comment,
    //     // try_skip_whitespace,
    //     EnclosingPairs,
    //     EnclosingSplit
    // };
    
    // pub fn skip_comments_and_whitespace (data: &[u8], start_index: usize) -> usize {
    //     // Restricting the search range to the slice starting at start_index
    //     let target = &data[start_index..];

    //     let chr = target[0] as char;
    //     if !(chr.is_whitespace() || chr == '/') {
    //         // Check to make sure the slice must begin with whitespace
    //         //      or comment opening character
    //         return 0;
    //     }

    //     // Regex to match whitespace and comments
    //     let re = regex::Regex::new("(\\s|(//.*\n)|(/\\*(.|\\s)*\\*/))+").unwrap();

    //     // Creating an iterater
    //     let matches = re.find(std::str::from_utf8(target).unwrap());

    //     matches.unwrap().end()
    // }


    // pub fn skip_string (data: &[u8], start_index: usize) -> usize {
    //     // Restricting the search range to the slice starting at start_index
    //     let target = &data[start_index..];

    //     let chr = target[0] as char;
    //     if !(chr == '\'' || chr == '"' || chr == '`') {
    //         // Check to make sure the slice must begin with whitespace
    //         //      or comment opening character
    //         return 0;
    //     }

    //     let regex_str = format!("{}(.|\\s)*[^\\\\]{}", chr, chr);

    //     // Regex to match whitespace and comments
    //     let re = regex::Regex::new(regex_str.as_str()).unwrap();

    //     // Creating an iterater
    //     let matches = re.find(std::str::from_utf8(target).unwrap());

    //     matches.unwrap().end()
    // }
   


    // #[derive(Debug, PartialEq, Eq)]
    // pub enum FluffType {
    //     Whitespace,
    //     Comment,
    //     String,
    //     None
    // }

    // /// # try_skip_fluff
    // ///
    // /// A function to be used when parsing fjs element used to skip over the fluff of vanilla js stuff
    // ///      like comments, strings, and whitespace
    // ///
    // /// Takes in a data array, a starting index, and a table for enclosing pairs, and returns an ending
    // ///     index of the fluff, and the type of fluff that we skipped
    // /// 
    // /// # Parameters -- 
    // /// * `data: &[u8]`                    -- byte string data
    // /// * `start_index: usize`             -- beginning offset of the byte string -- starting point of the search
    // /// * `pairs_lookup: &EnclosingPairs`  -- lookup table for enclosing pairs (in this case opening and closing strings ''', '"', and '`')
    // /// 
    // /// # Return --  
    // /// * `usize`                          -- ending index of the fluff section, or 0 if the targeted section does not begin with fluff
    // /// * `FluffType`                      -- the type of fluff that was skipp over, or FluffType::None if the targeed section does not begin with fluff
    // pub fn try_skip_fluff (
    //     data: &[u8], 
    //     start_index: usize, 
    //     pairs_lookup: &EnclosingPairs
    // ) -> (usize, FluffType) {
    //     let chr = data[start_index] as char;
        
    //     // Three cases to watch out for (and skip over):
    //     //      0. whitespace
    //     //      1. comments
    //     //      2. strings

    //     // Check whitespace
    //     let end = try_skip_whitespace(data, chr, start_index);
    //     if end != 0 {
    //         return (
    //             start_index + end + 1, 
    //             FluffType::Whitespace
    //         );
    //     }

    //     // Check comment:
    //     let end = try_skip_comment(data, chr, start_index);
    //     if end != 0 {
    //         return (
    //             start_index + end + 1,
    //             FluffType::Comment
    //         );
    //     }

    //     // Check string
    //     let end = try_skip_string(data, chr, start_index);
    //     if end != 0 {
    //         let (end, _) = find_enclosing_pair(data, chr, 0, pairs_lookup);
    //         // TODO: check the inside of the template string for ${} and parsable
    //         // TODO:        sections of fscript code in there
    //         // if chr == '`' {
    //         //     let splits = EnclosingSplit {
    //         //         before: &data[0..index],
    //         //         middle: &data[index+1..end],
    //         //         after: &data[end+1..data.len()],
    //         //         pair: ('`', '`')
    //         //     };


    //         // }

    //         // Move the index to the end of the string section
    //         return (
    //             start_index + end + 1, 
    //             FluffType::String
    //         );
    //     }
    //     return (0, FluffType::None);
    // }

    use regex::Regex;
    use regex::Match;




    // /// # skip_for_character
    // ///
    // /// A function to be used when parsing fjs element used to skip over the fluff of vanilla js
    // ///     comments and whitespace, to search for a character
    // ///
    // /// Used when you know what the next valid character should be, but there may be whitespace or comments
    // ///     between start_index and that character
    // ///
    // /// Takes in a data array, a starting index, a target characted, and a table for enclosing pairs, and returns 
    // ///     Some( index ) of the target character, if there are no invalid characters betweeen start_index and the 
    // ///     the target character, or None, if there is
    // /// 
    // /// # Parameters -- 
    // /// * `data:         &[u8]`            -- byte string data
    // /// * `start_index:  usize`            -- beginning offset of the byte string -- starting point of the search
    // /// * `search:       char`             -- target character to be searched
    // /// * `pairs_lookup: &EnclosingPairs`  -- lookup table for enclosing pairs (in this case opening and closing strings ''', '"', and '`')
    // /// 
    // /// # Return --  
    // /// * `Option<usize>`                  -- index of the target character, starting from start_index.  Or None, if there are invalid characters in the way.
    // pub fn skip_for_character (
    //     data:         &[u8], 
    //     start_index:  usize, 
    //     search:       char, 
    //     pairs_lookup: &EnclosingPairs
    // ) -> Option<usize> {

    //     // Localize start index as mutable
    //     let mut index = start_index;

    //     // Loop to find parentheses
    //     while index < data.len() {
    //         let chr = data[index] as char;
        
    //         // Three cases to look out for:
    //         //      0. character is target   --> return Some (index)
    //         //      1. whitespace / comments --> skip it
    //         //      2. anything else         --> some invalid character, return None

    //         // Check opening parenthesis
    //         if chr == search {
    //             Some( index );
    //         }

    //         if chr == '/' || chr.is_whitespace() {
    //             // Get the ending index of the whitespace / comment
    //             let end = skip_comments_and_whitespace(data, index);
    //             if end != 0 {
    //                 index += end;
    //             }
    //             else {  
    //                 // If end == 0, then the comment / whitespace was invalid
    //                 //      meaning that there is some invalid character
    //                 return None;
    //             }
    //         }
    //         else {
    //             return None;
    //         }

    //         // increment index
    //         index += 1;
    //     }
    //     // Target was not found, return None
    //     None
    // }


    // pub fn next_token_of_interest_2 <'a> (data: &'a str, token_lookup: &TokenLookup) -> (&'a str, TokensOfInterest) {
        

    //     // let token_begin_chars = | search: char | [ '&', '|', '^', '~', '=', '!', '>', '<', '+', '-', '*', '/', '%', '(', '[', ':', ',', '.', ']', ')' ].iter().find(|x| **x == search);
    //     // let 

    //     let mut last: TokensOfInterest      // the last token found
    //         = TokensOfInterest::None;
        
    //     let mut start: usize = 0;           // 

    //     // Get rid of all leading whitespace -- that is definitely not a part
    //     //      of a token    
    //     let data = data.trim_start();
        
    //     for end in 1..data.len()+1 {
    //         // Getting the current slice to inspect as a token
    //         let slice 
    //             = &data[0..end].as_bytes();
        



    //     }


    //     ("", last)
    // }


    // /// # Function to func the next largest token of interest in the string slice
    // /// 
    // pub fn next_token_of_interest <'a> (data: &'a str, token_lookup: &TokenLookup) -> (&'a str, TokensOfInterest) {
        
    //     let mut last: TokensOfInterest      // the last token found
    //         = TokensOfInterest::None;

    //     // Get rid of all leading whitespace -- that is definitely not a part
    //     //      of a token    
    //     let data = data.trim_start();
        
    //     for end in 1..data.len()+1 {
    //         // Getting the current slice to inspect as a token
    //         let slice 
    //             = &data[0..end].as_bytes();
            
    //         // println!("{}: {}", end, &data[0..end]);

    //         // Search the current slice in the token lookup table
    //         let cur = lookup_token (
    //             slice, 
    //             token_lookup
    //         );

    //         if cur  == TokensOfInterest::None 
    //         && last != TokensOfInterest::None {

    //             match last {
    //                 TokensOfInterest::In         |
    //                 TokensOfInterest::If         |
    //                 TokensOfInterest::Of         |
    //                 TokensOfInterest::New        |
    //                 TokensOfInterest::Switch     |
    //                 TokensOfInterest::Delete     |
    //                 TokensOfInterest::Typeof     |
    //                 TokensOfInterest::Instanceof => {
    //                     if !(data.as_bytes()[end] as char).is_alphabetic() {
    //                         return (&data[end-1..], last);
    //                     }
    //                     else { 
                            
    //                     }
    //                 },
    //                 _ => {
    //                     return (&data[end-1..], last);
    //                 }
    //             };

    //             // If current slice is not a token, but the last slice
    //             //      was a valid token, then the last token is the 
    //             //      first largest token in the slice
    //             return (&data[end-1..], last);
    //         }
    //         last = cur;
    //     }
    //     // Return an empty string, and whatever token that the last
    //     //      slice evaluated to
    //     ("", last)
    // }